{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/luviSu96Xi6ag1bWZJBn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhreyaa/software-systems/blob/main/Question_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MT2023179 SHREYA CHAVAN"
      ],
      "metadata": {
        "id": "o2ZH6dJ-odFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 Logistic Regression"
      ],
      "metadata": {
        "id": "TWPM3-Qiog9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define the sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Define the logistic regression training function\n",
        "def train_logistic_regression(X, y, learning_rate, num_iterations):\n",
        "    # Initialize weights and bias\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    bias = 0\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        # Calculate the linear combination of weights and features\n",
        "        z = np.dot(X, theta) + bias\n",
        "\n",
        "        # Apply the sigmoid function to get probabilities\n",
        "        predictions = sigmoid(z)\n",
        "\n",
        "        # Calculate the gradient of the loss with respect to theta and bias\n",
        "        dw = (1 / m) * np.dot(X.T, (predictions - y))\n",
        "        db = (1 / m) * np.sum(predictions - y)\n",
        "\n",
        "        # Update weights and bias\n",
        "        theta -= learning_rate * dw\n",
        "        bias -= learning_rate * db\n",
        "\n",
        "    return theta, bias\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/football.csv\")\n",
        "\n",
        "# Select the features (X_train) and labels (y_train)\n",
        "X_train = data[['defending', 'attacking_crossing', 'attacking_finishing',\n",
        "                'attacking_heading_accuracy', 'attacking_short_passing',\n",
        "                'attacking_volleys','defending_marking_awareness',\n",
        "                'defending_standing_tackle', 'defending_sliding_tackle']].values\n",
        "y_train = data['contribution_type'].values\n",
        "\n",
        "# Train the logistic regression model\n",
        "learning_rate = 0.01\n",
        "num_iterations = 10000\n",
        "theta, bias = train_logistic_regression(X_train, y_train, learning_rate, num_iterations)"
      ],
      "metadata": {
        "id": "G8DjLXaXl1Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making predictions on the trained model"
      ],
      "metadata": {
        "id": "UF9PwXuMpEGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test should have the same number of features as X_train\n",
        "\n",
        "test_data = pd.read_csv(\"/content/footballtestdata.csv\")\n",
        "\n",
        "# Select the features for testing (X_test)\n",
        "X_test = test_data[['defending', 'attacking_crossing', 'attacking_finishing',\n",
        "                'attacking_heading_accuracy', 'attacking_short_passing',\n",
        "                'attacking_volleys','defending_marking_awareness',\n",
        "                'defending_standing_tackle', 'defending_sliding_tackle']].values\n",
        "\n",
        "# Assuming 'contribution type' labels in text form, convert them to numerical labels (0 and 1)\n",
        "y_test = (test_data['contribution_type'])\n",
        "\n",
        "# Make predictions on the testing data\n",
        "def predict(X, theta, bias):\n",
        "    z = np.dot(X, theta) + bias\n",
        "    predictions = sigmoid(z)\n",
        "    return np.round(predictions)  # Round to 0 or 1\n",
        "\n",
        "y_pred = predict(X_test, theta, bias)"
      ],
      "metadata": {
        "id": "dt_o611SmvMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the F1 score, accuracy score, and confusion matrix to evaluate the model's performance"
      ],
      "metadata": {
        "id": "hZGpsBrRpG-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_test and y_pred are your ground truth and predicted labels, respectively.\n",
        "\n",
        "# Calculate accuracy\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    total = len(y_true)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "accuracy = calculate_accuracy(y_test, y_pred)\n",
        "\n",
        "# Calculate precision\n",
        "def calculate_precision(y_true, y_pred):\n",
        "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    return precision\n",
        "\n",
        "precision = calculate_precision(y_test, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "def calculate_recall(y_true, y_pred):\n",
        "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    false_negatives = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    return recall\n",
        "\n",
        "recall = calculate_recall(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "def calculate_f1_score(precision, recall):\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1_score\n",
        "\n",
        "f1_score = calculate_f1_score(precision, recall)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "def calculate_confusion_matrix(y_true, y_pred):\n",
        "    true_positives = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    true_negatives = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    false_negatives = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    confusion_matrix = np.array([[true_negatives, false_positives], [false_negatives, true_positives]])\n",
        "    return confusion_matrix\n",
        "\n",
        "confusion_matrix = calculate_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRn-7MAWmNwE",
        "outputId": "8efd3613-156e-422e-9740-fd0b42604465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0\n",
            "Precision: nan\n",
            "Recall: nan\n",
            "F1 Score: nan\n",
            "Confusion Matrix:\n",
            "[[0 0]\n",
            " [0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-51aacc07c500>:16: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  precision = true_positives / (true_positives + false_positives)\n",
            "<ipython-input-32-51aacc07c500>:25: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  recall = true_positives / (true_positives + false_negatives)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1RihPaOxrh92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}